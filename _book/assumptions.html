<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Assumptions and statistical models | staRters; An introductory workshop for analysis of data with R</title>
  <meta name="description" content="HU Ontwikkelfestival, 2-4 November, 2020" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Assumptions and statistical models | staRters; An introductory workshop for analysis of data with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="HU Ontwikkelfestival, 2-4 November, 2020" />
  <meta name="github-repo" content="uashogeschoolutrecht/staRters" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Assumptions and statistical models | staRters; An introductory workshop for analysis of data with R" />
  
  <meta name="twitter:description" content="HU Ontwikkelfestival, 2-4 November, 2020" />
  

<meta name="author" content="Marc A.T. Teunis, PhD" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="importingdata.html"/>
<link rel="next" href="sampling-bootstrapping.html"/>
<script src="libs/header-attrs-2.4/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.15/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<script src="libs/d3-5.7.0/d3.min.js"></script>
<script src="libs/d3-lasso-0.0.5/d3-lasso.min.js"></script>
<link href="libs/ggiraphjs-0.3.0/ggiraphjs.min.css" rel="stylesheet" />
<script src="libs/ggiraphjs-0.3.0/ggiraphjs.min.js"></script>
<script src="libs/girafe-binding-0.7.8/girafe.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis with R for staRters</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="why-r.html"><a href="why-r.html"><i class="fa fa-check"></i><b>2</b> Why use R?</a></li>
<li class="chapter" data-level="3" data-path="gettingstarted.html"><a href="gettingstarted.html"><i class="fa fa-check"></i><b>3</b> Getting Started</a></li>
<li class="chapter" data-level="4" data-path="edacase.html"><a href="edacase.html"><i class="fa fa-check"></i><b>4</b> Case Example</a></li>
<li class="chapter" data-level="5" data-path="introrstudio.html"><a href="introrstudio.html"><i class="fa fa-check"></i><b>5</b> Introduction to RStudio</a></li>
<li class="chapter" data-level="6" data-path="rmarkdown.html"><a href="rmarkdown.html"><i class="fa fa-check"></i><b>6</b> Literate Programming with RMarkdown</a></li>
<li class="chapter" data-level="7" data-path="intror.html"><a href="intror.html"><i class="fa fa-check"></i><b>7</b> Introduction to R</a></li>
<li class="chapter" data-level="8" data-path="recursivevectors.html"><a href="recursivevectors.html"><i class="fa fa-check"></i><b>8</b> Lists and dataframes</a></li>
<li class="chapter" data-level="9" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>9</b> Visualize &amp; Explore Data</a></li>
<li class="chapter" data-level="10" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>10</b> Data Wrangling</a></li>
<li class="chapter" data-level="11" data-path="tidydata.html"><a href="tidydata.html"><i class="fa fa-check"></i><b>11</b> Tidy Data</a></li>
<li class="chapter" data-level="12" data-path="importingdata.html"><a href="importingdata.html"><i class="fa fa-check"></i><b>12</b> Importing data</a></li>
<li class="chapter" data-level="13" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>13</b> Assumptions and statistical models</a></li>
<li class="chapter" data-level="14" data-path="sampling-bootstrapping.html"><a href="sampling-bootstrapping.html"><i class="fa fa-check"></i><b>14</b> Sampling, Probability distributions and bootstrapping</a></li>
<li class="chapter" data-level="15" data-path="resources.html"><a href="resources.html"><i class="fa fa-check"></i><b>15</b> Resources</a></li>
<li class="divider"></li>
<li><a href="https://github.com/uashogeschoolutrecht/staRters" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">staRters; An introductory workshop for analysis of data with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="assumptions" class="section level1" number="13">
<h1><span class="header-section-number">Chapter 13</span> Assumptions and statistical models</h1>
<div id="references" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> References</h2>
<p>Input for content of this chapter was derived from <span class="citation">(Andy Field <a href="#ref-dsur" role="doc-biblioref">2012</a>)</span>, <span class="citation">(Kuhn and Johnson <a href="#ref-apm" role="doc-biblioref">2018</a>)</span>, <span class="citation">(McElreath <a href="#ref-rethinking" role="doc-biblioref">2020</a>)</span>, [adventr], Applied Predictive Modelling from Max Kuhn and</p>
<p><a href="https://cran.r-project.org/web/packages/dlookr/vignettes/EDA.html" class="uri">https://cran.r-project.org/web/packages/dlookr/vignettes/EDA.html</a> and <a href="https://tylerburleigh.com/blog/surviving-the-titanic-with-r-caret/" class="uri">https://tylerburleigh.com/blog/surviving-the-titanic-with-r-caret/</a></p>
<p><a href="https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Continous-Random-Variables/The-Standard-Normal-Distribution/The-Standard-Normal-Distribution-An-Example/index.html" class="uri">https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Continous-Random-Variables/The-Standard-Normal-Distribution/The-Standard-Normal-Distribution-An-Example/index.html</a></p>
<p><a href="http://msenux2.redwoods.edu/MathDept/R/StandardNormal.php" class="uri">http://msenux2.redwoods.edu/MathDept/R/StandardNormal.php</a></p>
<p><a href="http://www.cookbook-r.com/Manipulating_data/Changing_the_order_of_levels_of_a_factor/" class="uri">http://www.cookbook-r.com/Manipulating_data/Changing_the_order_of_levels_of_a_factor/</a></p>
<p><a href="http://rstudio-pubs-static.s3.amazonaws.com/78857_86c2403ca9c146ba8fcdcda79c3f4738.html" class="uri">http://rstudio-pubs-static.s3.amazonaws.com/78857_86c2403ca9c146ba8fcdcda79c3f4738.html</a></p>
</div>
<div id="introduction" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Introduction</h2>
<p>W ith this chapter, I hope to inspire the reader to try and use models (statistical models if you will) to do Exploratory Data Analysis. Although EDA is often said not to depend on statistics, I do not agree. Statistical inference and predictive modeling can learn you a lot about your data and provide valuable inside on where to go next in you analysis.
There are many good works on statistics and R. Three books stand out and provide valuable information for this chapter:
<span class="citation">(Andy Field <a href="#ref-dsur" role="doc-biblioref">2012</a>)</span>, <span class="citation">(Kuhn and Johnson <a href="#ref-apm" role="doc-biblioref">2018</a>)</span>, <span class="citation">(McElreath <a href="#ref-rethinking" role="doc-biblioref">2020</a>)</span>. For a complete overview and solid work on using R for inference: <span class="citation">(Field <a href="#ref-adventr" role="doc-biblioref">2019</a>)</span>, <span class="citation">(<span class="citeproc-not-found" data-reference-id="moderndive"><strong>???</strong></span>)</span> and <span class="citation">(Andy Field <a href="#ref-dsur" role="doc-biblioref">2012</a>)</span></p>
<p>We will also examine some of the official statistical applications of R in lab 6b and 6c</p>
</div>
<div id="packages" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Packages</h2>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb803-1"><a href="assumptions.html#cb803-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb803-2"><a href="assumptions.html#cb803-2"></a><span class="kw">library</span>(AppliedPredictiveModeling)</span>
<span id="cb803-3"><a href="assumptions.html#cb803-3"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb803-4"><a href="assumptions.html#cb803-4"></a><span class="kw">library</span>(devtools)</span>
<span id="cb803-5"><a href="assumptions.html#cb803-5"></a><span class="kw">library</span>(pastecs)</span>
<span id="cb803-6"><a href="assumptions.html#cb803-6"></a><span class="kw">library</span>(car)</span>
<span id="cb803-7"><a href="assumptions.html#cb803-7"></a><span class="kw">library</span>(e1071)</span>
<span id="cb803-8"><a href="assumptions.html#cb803-8"></a><span class="kw">library</span>(pastecs)</span>
<span id="cb803-9"><a href="assumptions.html#cb803-9"></a><span class="kw">library</span>(caret)</span>
<span id="cb803-10"><a href="assumptions.html#cb803-10"></a><span class="co"># install_github(&quot;profandyfield/adventr&quot;)</span></span>
<span id="cb803-11"><a href="assumptions.html#cb803-11"></a><span class="co"># library(adventr)</span></span>
<span id="cb803-12"><a href="assumptions.html#cb803-12"></a><span class="co"># devtools::install_github(&quot;tidymodels/parsnip&quot;)</span></span>
<span id="cb803-13"><a href="assumptions.html#cb803-13"></a><span class="kw">library</span>(parsnip)</span>
<span id="cb803-14"><a href="assumptions.html#cb803-14"></a><span class="kw">library</span>(tidymodels)</span>
<span id="cb803-15"><a href="assumptions.html#cb803-15"></a><span class="kw">library</span>(recipes)</span>
<span id="cb803-16"><a href="assumptions.html#cb803-16"></a><span class="kw">library</span>(moderndive)</span>
<span id="cb803-17"><a href="assumptions.html#cb803-17"></a><span class="kw">library</span>(skimr)</span>
<span id="cb803-18"><a href="assumptions.html#cb803-18"></a><span class="kw">library</span>(gapminder)</span></code></pre></div>
</div>
<div id="model-assumptions" class="section level2" number="13.4">
<h2><span class="header-section-number">13.4</span> Model assumptions</h2>
<p>Every model has assumptions that are relevant for the applicability of a model. We must assume that a model is exactly what it is: a model and as such it is a representation of something else. In Data Science we use models to describe or even predict things about the world surrounding us.</p>
<p>In statistical inference and also for EDA, assumptions are important. They are the prerequisites for the applicability of the models we use. Assumptions for statistical inference and models can be requirements for a distribution type, variable type, number of groups to compare, equality of variance. Usually we consider a statistical test invalid if it is performed on data that does not meet one more assumptions. A robust test is relatively uninfluenced by one or more assumptions. In this chapter, I will not extensively address statistical inference and robustness. We will however learn how to assess whether some common assumptions like distribution requirements and equality of variance between groups are met. After which we will explore how to use models to do EDA and learn some statistical methods to do inference.</p>
</div>
<div id="variable-types" class="section level2" number="13.5">
<h2><span class="header-section-number">13.5</span> Variable types</h2>
<p>Just as a reminder, there are a number of variable types usually represented in one dataset. We already saw many different types. Basically, if we want to do statistics or modeling using machine learning we have to learn to recognize the different types of variables. A good recap can be foud <a href="https://statistics.laerd.com/statistical-guides/types-of-variable.php">here:</a></p>
<p>In R terminology we can discriminate between these as:</p>
<div id="categorical" class="section level3" number="13.5.1">
<h3><span class="header-section-number">13.5.1</span> Categorical:</h3>
<ul>
<li>Character: A variable with a set of discrete outcomes that can be ordered (ordinal) or have an arbitrary order.</li>
<li>A Factor: Usually derived from a categorical variable. Usually conveys something on the grouping structure of the data. Can be ordinal (ordered factor), nominal (unordered factor) or dichotomous (ordered or unordered, two levels). A dichotomous factor is especially of interest when dealing with classification problems. Dichotomous (dependent) variables are usually easier to train a machine learning model for.</li>
<li>A logical variable type is by definition dichotomous in nature and can contain the values TRUE or FALSE (or 1 and 0) only.</li>
</ul>
</div>
<div id="continuous" class="section level3" number="13.5.2">
<h3><span class="header-section-number">13.5.2</span> Continuous:</h3>
<ul>
<li>A numeric variable can be an integer (ratio) variable or an interval variable. In R we call interval variables ‘doubles’. Statistically, there is a strong relationship between</li>
</ul>
<p>Depending on the analysis method used and the question at hand we can have one or multiple independent (predictor) variables. Usually we have one dependent variable for a specific analysis question. R has a convenient formula interface that is used in many statistical methods and machine learning implementations. The formula interface of R denotes dependent and independent (or so-called ‘predictor’ variables) as:</p>
<p><span class="math inline">\(formula = dependent \sim predictor\)</span></p>
<p>or if multiple predictors are used:
<span class="math inline">\(formula = dependent \sim predictor1 + predictor2 + predictor3\)</span></p>
<p>or, if used in comparing the effect of multiple independent variables on the group means, e.g. in an ANOVA. Below we specify the effect of predictor1 on dependent, the effect of predictor2 on dependent and the interaction of predictor1 and predictor2 on dependent:
<span class="math inline">\(formula = dependent \sim predictor1 * predictor2\)</span></p>
<p>We will see some examples of this in Lab 6b and 6c.</p>
</div>
</div>
<div id="the-normal-distribution" class="section level2" number="13.6">
<h2><span class="header-section-number">13.6</span> The normal distribution</h2>
<p>In statistics, there is a lot of fuzz around the Normal Distribution:
Many continuous variables follow a specific distribution called the Normal Distribution. Because many inferential statistical methods rely upon a variable being normally distributed (or at least approach it), we will look in more detail at this type of distribution.</p>
<p>A distribution of a variable <span class="math inline">\(x\)</span> is said to be normally distributed if the frequency distribution of <span class="math inline">\(x\)</span> can be represented by this formula:</p>
<p><span class="math inline">\(f(x) = \frac{1}{\sqrt{2\pi\delta^2}} exp(-\frac{1}{2}(x-\mu)^2/\delta)\)</span></p>
<p>The details of this formula are not so important here and we will not do any mathematical derivations. One remarkable thing about this formula stands out however. Are you able to spot what this is?…</p>
<p>Yes, you probably spotted the fact that a normal distribution is marked only by the mean (<span class="math inline">\(\mu\)</span>) and the standard deviation (<span class="math inline">\(\delta\)</span>) of a variable.</p>
<p>A normal distribution with <span class="math inline">\(\mu = 0\)</span> and <span class="math inline">\(\delta = 1\)</span> is called the <code>Standard Normal Distribution</code></p>
<div id="exercise-1-the-standard-normal-distribution" class="section level3 unnumbered" number="">
<h3><mark><strong>EXERCISE 1; The Standard Normal Distribution</strong></mark></h3>
<p>In R we can easily experiment with the characteristics of the Normal Distribution</p>
<ol style="list-style-type: upper-alpha">
<li><p>Rewrite the function of the Normal Frequency Distribution for <span class="math inline">\(\mu = 0\)</span> and <span class="math inline">\(\delta = 1\)</span></p></li>
<li><p>The code below simulates the creation of 200 uniformly distributed random values of <code>x</code> between -4 and +4). The respective resulting graph is a graphical representation of the Standard Normal Distribution. To generate a sequence of normally distributed random values we can use the <code>rnorm()</code> function. This function uses the above-mentioned Normal Frequency Distribution Function under the hood, so we do not have to worry about the mathematics.</p></li>
</ol>
<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb804-1"><a href="assumptions.html#cb804-1"></a><span class="kw">set.seed</span>(<span class="dv">1234999</span>)</span>
<span id="cb804-2"><a href="assumptions.html#cb804-2"></a>normals &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">100</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span></span>
<span id="cb804-3"><a href="assumptions.html#cb804-3"></a><span class="st">  </span><span class="kw">enframe</span>()</span>
<span id="cb804-4"><a href="assumptions.html#cb804-4"></a></span>
<span id="cb804-5"><a href="assumptions.html#cb804-5"></a><span class="co">## determine mean and sd of our simulated random normals (should approach 0 and 1 resp.)</span></span>
<span id="cb804-6"><a href="assumptions.html#cb804-6"></a><span class="kw">mean</span>(normals<span class="op">$</span>value)</span></code></pre></div>
<pre><code>## [1] 0.04725584</code></pre>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="assumptions.html#cb806-1"></a><span class="kw">sd</span>(normals<span class="op">$</span>value)</span></code></pre></div>
<pre><code>## [1] 0.9672451</code></pre>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="assumptions.html#cb808-1"></a><span class="co">## </span></span>
<span id="cb808-2"><a href="assumptions.html#cb808-2"></a><span class="kw">hist</span>(normals<span class="op">$</span>value)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb809-1"><a href="assumptions.html#cb809-1"></a><span class="co">## plot</span></span>
<span id="cb809-2"><a href="assumptions.html#cb809-2"></a>normals <span class="op">%&gt;%</span></span>
<span id="cb809-3"><a href="assumptions.html#cb809-3"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>value)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb809-4"><a href="assumptions.html#cb809-4"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb809-5"><a href="assumptions.html#cb809-5"></a><span class="st">  </span><span class="kw">xlim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>)) </span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb810-1"><a href="assumptions.html#cb810-1"></a><span class="co">## resampling</span></span>
<span id="cb810-2"><a href="assumptions.html#cb810-2"></a></span>
<span id="cb810-3"><a href="assumptions.html#cb810-3"></a>sample_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">sample_n</span>(normals, <span class="dv">100</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb810-4"><a href="assumptions.html#cb810-4"></a><span class="kw">mean</span>(sample_<span class="dv">1</span><span class="op">$</span>value)</span></code></pre></div>
<pre><code>## [1] 0.1968376</code></pre>
<div class="sourceCode" id="cb812"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb812-1"><a href="assumptions.html#cb812-1"></a>sample_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">sample_n</span>(normals, <span class="dv">100</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb812-2"><a href="assumptions.html#cb812-2"></a><span class="kw">mean</span>(sample_<span class="dv">2</span><span class="op">$</span>value)  </span></code></pre></div>
<pre><code>## [1] 0.003821869</code></pre>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb814-1"><a href="assumptions.html#cb814-1"></a><span class="co">## homework:</span></span>
<span id="cb814-2"><a href="assumptions.html#cb814-2"></a><span class="co">## create a function that generates 1000 boostrapped samples of the mean form the &#39;normal$value&#39; sample</span></span>
<span id="cb814-3"><a href="assumptions.html#cb814-3"></a><span class="co">## plot a histogram of the 1000 mean-estimates</span></span></code></pre></div>
<ol start="3" style="list-style-type: upper-alpha">
<li>Add the <code>mean</code> and the <code>sd</code> as a vertical (dashed) line to the graph from B)</li>
</ol>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb815-1"><a href="assumptions.html#cb815-1"></a>normals <span class="op">%&gt;%</span></span>
<span id="cb815-2"><a href="assumptions.html#cb815-2"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>value)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb815-3"><a href="assumptions.html#cb815-3"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb815-4"><a href="assumptions.html#cb815-4"></a><span class="st">  </span><span class="kw">xlim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>)) <span class="op">+</span></span>
<span id="cb815-5"><a href="assumptions.html#cb815-5"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(normals<span class="op">$</span>value), <span class="dt">colour =</span> <span class="st">&#39;blue&#39;</span>, <span class="dt">linetype =</span> <span class="st">&#39;dashed&#39;</span>) <span class="op">+</span></span>
<span id="cb815-6"><a href="assumptions.html#cb815-6"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">sd</span>(normals<span class="op">$</span>value), <span class="dt">colour =</span> <span class="st">&#39;darkblue&#39;</span>, <span class="dt">linetype =</span> <span class="st">&#39;dashed&#39;</span>) <span class="op">+</span></span>
<span id="cb815-7"><a href="assumptions.html#cb815-7"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="op">-</span><span class="kw">sd</span>(normals<span class="op">$</span>value), <span class="dt">colour =</span> <span class="st">&#39;darkblue&#39;</span>, <span class="dt">linetype =</span> <span class="st">&#39;dashed&#39;</span>)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/include%20is%20FALSE-1.png" width="672" /></p>
<ol start="4" style="list-style-type: upper-alpha">
<li>Why are the mean and sd of the simulated data (<code>value</code> variable in the <code>normals</code> data frame not exactly equal to 0 and 1 respectively?</li>
</ol>
</div>
<div id="exercise-end--" class="section level3 unnumbered" number="">
<h3>—- EXERCISE END —-</h3>
</div>
</div>
<div id="investigating-your-own-data" class="section level2" number="13.7">
<h2><span class="header-section-number">13.7</span> Investigating your own data</h2>
<p>To see if your own data is approaching a normal distribution we can start with plotting the density distribution of your dependent variable. Let’s assume (I know it is hard) that we collect data on a number of cars ;-). On the basis of the data for miles per gallon we would like to get a prediction how these data would look if they would follow a normal distribution.</p>
<div class="sourceCode" id="cb816"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb816-1"><a href="assumptions.html#cb816-1"></a><span class="kw">ggplot</span>(mtcars, <span class="kw">aes</span>(<span class="dt">x =</span> mpg)) <span class="op">+</span></span>
<span id="cb816-2"><a href="assumptions.html#cb816-2"></a><span class="kw">stat_function</span>(</span>
<span id="cb816-3"><a href="assumptions.html#cb816-3"></a><span class="dt">fun =</span> dnorm,</span>
<span id="cb816-4"><a href="assumptions.html#cb816-4"></a><span class="dt">args =</span> <span class="kw">with</span>(mtcars, <span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(mpg), <span class="dt">sd =</span> <span class="kw">sd</span>(mpg)))</span>
<span id="cb816-5"><a href="assumptions.html#cb816-5"></a>) <span class="op">+</span><span class="st"> </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;Miles per gallon&quot;</span>)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We can than overlay the actual distribution as a histogram</p>
<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb817-1"><a href="assumptions.html#cb817-1"></a><span class="kw">ggplot</span>(mtcars, <span class="kw">aes</span>(<span class="dt">x =</span> mpg)) <span class="op">+</span></span>
<span id="cb817-2"><a href="assumptions.html#cb817-2"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb817-3"><a href="assumptions.html#cb817-3"></a>    <span class="dt">fun =</span> dnorm,</span>
<span id="cb817-4"><a href="assumptions.html#cb817-4"></a>    <span class="dt">args =</span> <span class="kw">with</span>(mtcars, <span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(mpg), <span class="dt">sd =</span> <span class="kw">sd</span>(mpg)))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb817-5"><a href="assumptions.html#cb817-5"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;Miles per gallon&quot;</span>) <span class="op">+</span></span>
<span id="cb817-6"><a href="assumptions.html#cb817-6"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y=</span>..density..),      </span>
<span id="cb817-7"><a href="assumptions.html#cb817-7"></a>                   <span class="dt">binwidth =</span> <span class="dv">1</span>,</span>
<span id="cb817-8"><a href="assumptions.html#cb817-8"></a>                   <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb818-1"><a href="assumptions.html#cb818-1"></a><span class="co">## or density</span></span>
<span id="cb818-2"><a href="assumptions.html#cb818-2"></a><span class="kw">ggplot</span>(mtcars, <span class="kw">aes</span>(<span class="dt">x =</span> mpg)) <span class="op">+</span></span>
<span id="cb818-3"><a href="assumptions.html#cb818-3"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb818-4"><a href="assumptions.html#cb818-4"></a>    <span class="dt">fun =</span> dnorm,</span>
<span id="cb818-5"><a href="assumptions.html#cb818-5"></a>    <span class="dt">args =</span> <span class="kw">with</span>(mtcars, <span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(mpg), <span class="dt">sd =</span> <span class="kw">sd</span>(mpg)))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb818-6"><a href="assumptions.html#cb818-6"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;Miles per gallon&quot;</span>) <span class="op">+</span></span>
<span id="cb818-7"><a href="assumptions.html#cb818-7"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">y=</span>..density..),      </span>
<span id="cb818-8"><a href="assumptions.html#cb818-8"></a>                   <span class="dt">binwidth =</span> <span class="dv">1</span>,</span>
<span id="cb818-9"><a href="assumptions.html#cb818-9"></a>                   <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: Ignoring unknown parameters: binwidth</code></pre>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<p>Here we can see that the <code>miles per gallon (mpg)</code> variable somewhat deviates from the the expected curve. The red curve that is displayed shows some additional observation between 25 and 35 mpg that were not ‘predicted’ by the normal distribution curve. The actual mean is also somewhat higher than the ‘predicted’ mean. We call this ‘scewing’. Here the observations are skewed to the right. The actual mean lies to the right of the predicted mean.</p>
<p>As long as the deviation is ‘not to big’ we can safely assume normality.</p>
<p><strong>Preparing data for statistical analysis or predictive modeling always means that you have to study the data distributions. Each modeling or inference technique has assumptions that more or less influence the usefulness of the method (an the validity of the conclusions), if these assumptions are violated.</strong></p>
<p>We will later see that there are also formal ways of checking normality with a statistical test, but always look at the graphs too!</p>
</div>
<div id="using-normal-distributions-in-practice" class="section level2" number="13.8">
<h2><span class="header-section-number">13.8</span> Using normal distributions in practice</h2>
<p>The mtcars dataset is all well for examples but not very exciting and we leave it behind now.</p>
<p>Let’s look at a real world example where a number of ‘features’ (you could also call them predictors) were collected from a larger number of students.
This dataset was derived from <a href="https://www.geo.fu-berlin.de/en/v/soga/">Hartmann, K., Krois, J., Waske, B. (2018): E-Learning Project SOGA: Statistics and Geospatial Data Analysis. Department of Earth Sciences, Freie Universitaet Berlin.</a></p>
<div id="exercise-2-using-distributions-to-do-predictions" class="section level3 unnumbered" number="">
<h3><mark><strong>EXERCISE 2; Using distributions to do predictions</strong></mark></h3>
<p>Assuming a variable follows a normal distribution leaves us with the possibility to assess the probability for which a certain value (or range of values) for x is to be observed, under the assumption of normality. This may sounds a bit cryptic, but I will show you an example. After that we will move on to use the normal distribution to compare if the means of two distributions are the same or different.</p>
</div>
<div id="example-data" class="section level3" number="13.8.1">
<h3><span class="header-section-number">13.8.1</span> Example data</h3>
<p>The students dataset can be found via this url: <code>https://userpage.fu-berlin.de/soga/200/2010_data_sets/students.csv</code></p>
<ol style="list-style-type: upper-alpha">
<li><p>Download the data and load it into a tibble called <code>data_students</code></p></li>
<li><p>Explore the variable names and write a short data-journal on which is what (we will need this for later use)</p></li>
</ol>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb820-1"><a href="assumptions.html#cb820-1"></a><span class="kw">names</span>(data_students)</span></code></pre></div>
<pre><code>##  [1] &quot;stud.id&quot;         &quot;name&quot;            &quot;gender&quot;          &quot;age&quot;            
##  [5] &quot;height&quot;          &quot;weight&quot;          &quot;religion&quot;        &quot;nc.score&quot;       
##  [9] &quot;semester&quot;        &quot;major&quot;           &quot;minor&quot;           &quot;score1&quot;         
## [13] &quot;score2&quot;          &quot;online.tutorial&quot; &quot;graduated&quot;       &quot;salary&quot;</code></pre>
<ol start="3" style="list-style-type: upper-alpha">
<li><p>Explore the <code>height</code>, <code>weight</code>, <code>age</code> and <code>gender</code> variables individually and their relationship using at least a scatter plot with color aesthetics and facets if necessary. Especially study the data distributions for height.
<img src="ch11-assumptions_files/figure-html/unnamed-chunk-7-1.png" width="672" /><img src="ch11-assumptions_files/figure-html/unnamed-chunk-7-2.png" width="672" /><img src="ch11-assumptions_files/figure-html/unnamed-chunk-7-3.png" width="672" /><img src="ch11-assumptions_files/figure-html/unnamed-chunk-7-4.png" width="672" /><img src="ch11-assumptions_files/figure-html/unnamed-chunk-7-5.png" width="672" /></p></li>
<li><p>Generate a histogram of all the values in the <code>height</code>variable. Overlay this histogram with a predicted normal distribution.</p></li>
</ol>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb822-1"><a href="assumptions.html#cb822-1"></a>data_students <span class="op">%&gt;%</span></span>
<span id="cb822-2"><a href="assumptions.html#cb822-2"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> height)) <span class="op">+</span></span>
<span id="cb822-3"><a href="assumptions.html#cb822-3"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb822-4"><a href="assumptions.html#cb822-4"></a>    <span class="dt">fun =</span> dnorm,</span>
<span id="cb822-5"><a href="assumptions.html#cb822-5"></a>    <span class="dt">args =</span> <span class="kw">with</span>(data_students, <span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(height), <span class="dt">sd =</span> <span class="kw">sd</span>(height)))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb822-6"><a href="assumptions.html#cb822-6"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;Height&quot;</span>) <span class="op">+</span></span>
<span id="cb822-7"><a href="assumptions.html#cb822-7"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">y=</span>..density..),      </span>
<span id="cb822-8"><a href="assumptions.html#cb822-8"></a>                   <span class="dt">binwidth =</span> <span class="dv">1</span>,</span>
<span id="cb822-9"><a href="assumptions.html#cb822-9"></a>                   <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></span>
<span id="cb822-10"><a href="assumptions.html#cb822-10"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Density&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: Ignoring unknown parameters: binwidth</code></pre>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>**What is your conclusion about the shape of the actual distribution vs the predicted distribution, under assumtion of normality?</p>
<ol start="5" style="list-style-type: upper-alpha">
<li>Generate a histogram of the values in the <code>height</code>variable, by <code>gender</code> using color aesthetics. Overlay these histograms for their theoretical normal distributions.</li>
</ol>
<p><strong>TIP</strong></p>
<ul>
<li>Create two separate dataframes for the male and the femal data</li>
<li>Adopt the code above where we used the mtcars dataset to plot the actual and predicted (normal) distribution for males and female in a plot. Assign colors to discriminate between the sexes.</li>
</ul>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb824-1"><a href="assumptions.html#cb824-1"></a>data_males &lt;-<span class="st"> </span>data_students <span class="op">%&gt;%</span></span>
<span id="cb824-2"><a href="assumptions.html#cb824-2"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(gender <span class="op">==</span><span class="st"> &quot;Male&quot;</span>)</span>
<span id="cb824-3"><a href="assumptions.html#cb824-3"></a></span>
<span id="cb824-4"><a href="assumptions.html#cb824-4"></a>data_females &lt;-<span class="st"> </span>data_students <span class="op">%&gt;%</span></span>
<span id="cb824-5"><a href="assumptions.html#cb824-5"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(gender <span class="op">==</span><span class="st"> &quot;Female&quot;</span>)</span>
<span id="cb824-6"><a href="assumptions.html#cb824-6"></a></span>
<span id="cb824-7"><a href="assumptions.html#cb824-7"></a>data_students <span class="op">%&gt;%</span></span>
<span id="cb824-8"><a href="assumptions.html#cb824-8"></a><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> height)) <span class="op">+</span></span>
<span id="cb824-9"><a href="assumptions.html#cb824-9"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb824-10"><a href="assumptions.html#cb824-10"></a>    <span class="dt">fun =</span> dnorm,</span>
<span id="cb824-11"><a href="assumptions.html#cb824-11"></a>    <span class="dt">args =</span> <span class="kw">with</span>(data_males, <span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(height), <span class="dt">sd =</span> <span class="kw">sd</span>(height))),</span>
<span id="cb824-12"><a href="assumptions.html#cb824-12"></a>    <span class="dt">colour =</span> <span class="st">&quot;darkblue&quot;</span>) <span class="op">+</span></span>
<span id="cb824-13"><a href="assumptions.html#cb824-13"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb824-14"><a href="assumptions.html#cb824-14"></a>    <span class="dt">fun =</span> dnorm,</span>
<span id="cb824-15"><a href="assumptions.html#cb824-15"></a>    <span class="dt">args =</span> <span class="kw">with</span>(data_females, <span class="kw">c</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(height), <span class="dt">sd =</span> <span class="kw">sd</span>(height))),</span>
<span id="cb824-16"><a href="assumptions.html#cb824-16"></a>    <span class="dt">colour =</span> <span class="st">&quot;darkred&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb824-17"><a href="assumptions.html#cb824-17"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;Height&quot;</span>) <span class="op">+</span></span>
<span id="cb824-18"><a href="assumptions.html#cb824-18"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> gender))</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<ol start="7" style="list-style-type: upper-alpha">
<li>What is your conclusion on the total and split by gender distributions for the height variable in the <code>data_students</code> dataset in terms of assumptions met for normality?</li>
</ol>
</div>
<div id="exercise-end---1" class="section level3 unnumbered" number="">
<h3>—- EXERCISE END —-</h3>
</div>
<div id="checking-the-assumption-that-a-distribution-is-not-significantly-different-from-normal-in-a-more-formal-way" class="section level3" number="13.8.2">
<h3><span class="header-section-number">13.8.2</span> Checking the assumption that a distribution is not significantly different from normal in a more formal way</h3>
<p>One additional way to check normality is by plotting the actual quantiles vs the theoretical quantiles. This plot is called a QQ or ‘quantile-quantile’ plot. If the points (actual) lie close to the line (theoretical) this means that the distribution is fairly normal. If the deviation is big, this means that the distribution of your data is probably deviating from normality as well.</p>
<div class="sourceCode" id="cb825"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb825-1"><a href="assumptions.html#cb825-1"></a><span class="kw">qqnorm</span>(data_females<span class="op">$</span>height, <span class="dt">main =</span> <span class="st">&#39;Q-Q plot for the height of female students&#39;</span>)</span>
<span id="cb825-2"><a href="assumptions.html#cb825-2"></a><span class="kw">qqline</span>(data_females<span class="op">$</span>height, <span class="dt">col =</span> <span class="dv">3</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
<div id="performing-a-test-to-check-for-normality" class="section level2" number="13.9">
<h2><span class="header-section-number">13.9</span> Performing a test to check for normality</h2>
<p>We can formally assess whether a distribution adheres to the normality assumption with a statitical test called the ‘Shapiro’ test. Be aware that this test is only reliable when the amount of datapoints is not to big. Data with a huge number of observations tend to always approach normality.</p>
<p>Let’s execute the Shapiro test on our ‘students’ dataset. Here I use a bit more sofiscation to test all variables in the students dataset for normality, when we split by gender.</p>
<p>We use the ‘split’ -&gt; ‘nest’ -&gt; ‘iterate’ approach here.</p>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb826-1"><a href="assumptions.html#cb826-1"></a>data_students <span class="op">%&gt;%</span></span>
<span id="cb826-2"><a href="assumptions.html#cb826-2"></a><span class="st">  </span><span class="kw">group_by</span>(gender) <span class="op">%&gt;%</span></span>
<span id="cb826-3"><a href="assumptions.html#cb826-3"></a><span class="st">  </span><span class="kw">nest</span>() -&gt;<span class="st"> </span>data_nested_students</span>
<span id="cb826-4"><a href="assumptions.html#cb826-4"></a></span>
<span id="cb826-5"><a href="assumptions.html#cb826-5"></a>ind &lt;-<span class="st"> </span><span class="kw">map_lgl</span>(data_nested_students<span class="op">$</span>data[[<span class="dv">1</span>]], is.numeric) </span>
<span id="cb826-6"><a href="assumptions.html#cb826-6"></a></span>
<span id="cb826-7"><a href="assumptions.html#cb826-7"></a><span class="co">## Females  </span></span>
<span id="cb826-8"><a href="assumptions.html#cb826-8"></a><span class="kw">map</span>(data_nested_students<span class="op">$</span>data[[<span class="dv">1</span>]][, ind], shapiro.test) </span></code></pre></div>
<pre><code>## $stud.id
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.95535, p-value &lt; 2.2e-16
## 
## 
## $age
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.46413, p-value &lt; 2.2e-16
## 
## 
## $height
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.99824, p-value = 0.0001472
## 
## 
## $weight
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.98563, p-value &lt; 2.2e-16
## 
## 
## $nc.score
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.94027, p-value &lt; 2.2e-16
## 
## 
## $score1
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.97164, p-value &lt; 2.2e-16
## 
## 
## $score2
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.97175, p-value &lt; 2.2e-16
## 
## 
## $online.tutorial
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.60985, p-value &lt; 2.2e-16
## 
## 
## $graduated
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.44587, p-value &lt; 2.2e-16
## 
## 
## $salary
## 
## 	Shapiro-Wilk normality test
## 
## data:  .x[[i]]
## W = 0.99787, p-value = 0.5636</code></pre>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb828-1"><a href="assumptions.html#cb828-1"></a>vector &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)</span>
<span id="cb828-2"><a href="assumptions.html#cb828-2"></a></span>
<span id="cb828-3"><a href="assumptions.html#cb828-3"></a><span class="kw">shapiro.test</span>(vector)</span></code></pre></div>
<pre><code>## 
## 	Shapiro-Wilk normality test
## 
## data:  vector
## W = 0.97016, p-value = 0.8924</code></pre>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb830-1"><a href="assumptions.html#cb830-1"></a><span class="co"># H0 = Shapiro = Distributie is normaal verdeeld</span></span>
<span id="cb830-2"><a href="assumptions.html#cb830-2"></a></span>
<span id="cb830-3"><a href="assumptions.html#cb830-3"></a><span class="co"># %&gt;%</span></span>
<span id="cb830-4"><a href="assumptions.html#cb830-4"></a><span class="co">#   map(., broom::tidy) %&gt;% dplyr::bind_rows() %&gt;%</span></span>
<span id="cb830-5"><a href="assumptions.html#cb830-5"></a><span class="co">#     mutate(var = names(data_nested_students$data[[1]][ind]),</span></span>
<span id="cb830-6"><a href="assumptions.html#cb830-6"></a><span class="co">#            gender = data_nested_students$gender[1]) -&gt; shapiros_female</span></span>
<span id="cb830-7"><a href="assumptions.html#cb830-7"></a><span class="co"># </span></span>
<span id="cb830-8"><a href="assumptions.html#cb830-8"></a><span class="co">## Males</span></span>
<span id="cb830-9"><a href="assumptions.html#cb830-9"></a><span class="kw">map</span>(data_nested_students<span class="op">$</span>data[[<span class="dv">2</span>]][, ind], shapiro.test) <span class="op">%&gt;%</span></span>
<span id="cb830-10"><a href="assumptions.html#cb830-10"></a><span class="st">  </span><span class="kw">map</span>(., broom<span class="op">::</span>tidy) <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">bind_rows</span>() <span class="op">%&gt;%</span></span>
<span id="cb830-11"><a href="assumptions.html#cb830-11"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">var =</span> <span class="kw">names</span>(data_nested_students<span class="op">$</span>data[[<span class="dv">2</span>]][ind]),</span>
<span id="cb830-12"><a href="assumptions.html#cb830-12"></a>           <span class="dt">gender =</span> data_nested_students<span class="op">$</span>gender[<span class="dv">2</span>]) -&gt;<span class="st"> </span>shapiros_male</span>
<span id="cb830-13"><a href="assumptions.html#cb830-13"></a></span>
<span id="cb830-14"><a href="assumptions.html#cb830-14"></a><span class="kw">map</span>(data_nested_students<span class="op">$</span>data[[<span class="dv">1</span>]][, ind], shapiro.test) <span class="op">%&gt;%</span></span>
<span id="cb830-15"><a href="assumptions.html#cb830-15"></a><span class="st">  </span><span class="kw">map</span>(., broom<span class="op">::</span>tidy) <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">bind_rows</span>() <span class="op">%&gt;%</span></span>
<span id="cb830-16"><a href="assumptions.html#cb830-16"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">var =</span> <span class="kw">names</span>(data_nested_students<span class="op">$</span>data[[<span class="dv">1</span>]][ind]),</span>
<span id="cb830-17"><a href="assumptions.html#cb830-17"></a>           <span class="dt">gender =</span> data_nested_students<span class="op">$</span>gender[<span class="dv">1</span>]) -&gt;<span class="st"> </span>shapiros_female</span>
<span id="cb830-18"><a href="assumptions.html#cb830-18"></a></span>
<span id="cb830-19"><a href="assumptions.html#cb830-19"></a></span>
<span id="cb830-20"><a href="assumptions.html#cb830-20"></a></span>
<span id="cb830-21"><a href="assumptions.html#cb830-21"></a>dplyr<span class="op">::</span><span class="kw">bind_rows</span>(shapiros_female, shapiros_male) <span class="op">%&gt;%</span></span>
<span id="cb830-22"><a href="assumptions.html#cb830-22"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p.value =</span> <span class="kw">round</span>(p.value, <span class="dv">6</span>)) -&gt;<span class="st"> </span>shapiros</span></code></pre></div>
<p>Let’s examine the results:
The H0 for the Shapiro is that the data is normally ditributed. If the p value is very low, we can reject this H0 and state that we have reason the believe that the data sampled was not derived from a normal distribution.</p>
<p>Let’s plot the results (p.values and variable names) in graph</p>
<div class="sourceCode" id="cb831"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb831-1"><a href="assumptions.html#cb831-1"></a>shapiros <span class="op">%&gt;%</span></span>
<span id="cb831-2"><a href="assumptions.html#cb831-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> var, <span class="dt">y =</span> <span class="kw">log10</span>(p.value))) <span class="op">+</span></span>
<span id="cb831-3"><a href="assumptions.html#cb831-3"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>) <span class="op">+</span></span>
<span id="cb831-4"><a href="assumptions.html#cb831-4"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>gender) <span class="op">+</span></span>
<span id="cb831-5"><a href="assumptions.html#cb831-5"></a><span class="st">  </span><span class="kw">coord_flip</span>()</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>We see here that this formal test may warrant a different conclusion than we previously drew from the qq-plot and the visual inspection of the distributions for the height variable.
Like most statistical significance tests, if the sample size is sufficiently large this test may detect even trivial departures from the null hypothesis (i.e., although there may be some statistically significant effect, it may be too small to be of any practical significance); thus, additional investigation of the effect size is typically advisable, e.g., a Q–Q plot in this case. A good rule is to give precedence to graphs and visual inspection, above formal (black box) tests. The number of observations here is pretty large (&gt; 4000 per group), so we might conclude that the distribution is normal for the weight variable and that the Shapiro test gives us an overestimation of departure form normality here.</p>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb832-1"><a href="assumptions.html#cb832-1"></a>data_students <span class="op">%&gt;%</span></span>
<span id="cb832-2"><a href="assumptions.html#cb832-2"></a><span class="st">  </span><span class="kw">group_by</span>(gender) <span class="op">%&gt;%</span></span>
<span id="cb832-3"><a href="assumptions.html#cb832-3"></a><span class="st">  </span><span class="kw">count</span>()</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
## # Groups:   gender [2]
##   gender     n
##   &lt;chr&gt;  &lt;int&gt;
## 1 Female  4110
## 2 Male    4129</code></pre>
<p>What is interesting from the Shapiro graph though is that the <code>salary</code> variable shows a rather large p.value (for females: 0.564). I did expect a variable such as income to be normaly distributed in this data.</p>
</div>
<div id="exercise-xx" class="section level2 unnumbered" number="">
<h2>EXERCISE xx</h2>
<p>Inspect the salary variable for both gender and show in a number of graphs how the distribution is related to <code>gender</code>, <code>age</code>, <code>graduated</code> and <code>major</code>. Look at the actual and theoretical distribution for <code>salary</code>, in relation to a major predictor. Can you see a pattern that is worhwhile investigating further?</p>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb834-1"><a href="assumptions.html#cb834-1"></a><span class="co">## distributions</span></span>
<span id="cb834-2"><a href="assumptions.html#cb834-2"></a>data_students <span class="op">%&gt;%</span></span>
<span id="cb834-3"><a href="assumptions.html#cb834-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> salary)) <span class="op">+</span></span>
<span id="cb834-4"><a href="assumptions.html#cb834-4"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> gender))</span></code></pre></div>
<pre><code>## Warning: Removed 6486 rows containing non-finite values (stat_density).</code></pre>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb836-1"><a href="assumptions.html#cb836-1"></a><span class="co">## actual vs theoretical</span></span>
<span id="cb836-2"><a href="assumptions.html#cb836-2"></a></span>
<span id="cb836-3"><a href="assumptions.html#cb836-3"></a></span>
<span id="cb836-4"><a href="assumptions.html#cb836-4"></a><span class="co">## Age and salary, vs major</span></span>
<span id="cb836-5"><a href="assumptions.html#cb836-5"></a>data_students <span class="op">%&gt;%</span></span>
<span id="cb836-6"><a href="assumptions.html#cb836-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> salary)) <span class="op">+</span></span>
<span id="cb836-7"><a href="assumptions.html#cb836-7"></a><span class="st">  </span><span class="kw">facet_grid</span>(gender <span class="op">~</span><span class="st"> </span>major) <span class="op">+</span></span>
<span id="cb836-8"><a href="assumptions.html#cb836-8"></a><span class="st">  </span><span class="kw">geom_point</span>()</span></code></pre></div>
<pre><code>## Warning: Removed 6486 rows containing missing values (geom_point).</code></pre>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-14-2.png" width="672" /></p>
<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb838-1"><a href="assumptions.html#cb838-1"></a><span class="kw">qqnorm</span>(data_females<span class="op">$</span>salary, <span class="dt">main =</span> <span class="st">&#39;Q-Q plot for the salary of female students&#39;</span>)</span>
<span id="cb838-2"><a href="assumptions.html#cb838-2"></a><span class="kw">qqline</span>(data_females<span class="op">$</span>salary, <span class="dt">col =</span> <span class="dv">3</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-14-3.png" width="672" /></p>
<p>If we look at the relationship between age, gender and major, can you think of an approach with which to study whether there is a true difference between gender, irrespective of major and whether there is true difference between majors, irrespective of gender. And whether gender and major are interacting factors, and whether age has any bearing on salary (in combination of the other factors, or considered in isolation)?</p>
<p>Write a short summary on how you would go about tackling the above analysis.</p>
<p>This plot might be of assistance:</p>
<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb839-1"><a href="assumptions.html#cb839-1"></a>data_students <span class="op">%&gt;%</span></span>
<span id="cb839-2"><a href="assumptions.html#cb839-2"></a><span class="st">  </span><span class="kw">group_by</span>(gender, major, age) <span class="op">%&gt;%</span></span>
<span id="cb839-3"><a href="assumptions.html#cb839-3"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean_salary =</span> <span class="kw">mean</span>(salary, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span></span>
<span id="cb839-4"><a href="assumptions.html#cb839-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> mean_salary)) <span class="op">+</span></span>
<span id="cb839-5"><a href="assumptions.html#cb839-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> gender)) <span class="op">+</span></span>
<span id="cb839-6"><a href="assumptions.html#cb839-6"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="kw">aes</span>(<span class="dt">group =</span> gender, <span class="dt">colour =</span> gender), <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="op">+</span></span>
<span id="cb839-7"><a href="assumptions.html#cb839-7"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>major)</span></code></pre></div>
<pre><code>## `summarise()` regrouping output by &#39;gender&#39;, &#39;major&#39; (override with `.groups` argument)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<pre><code>## Warning: Removed 178 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 178 rows containing missing values (geom_point).</code></pre>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="data-transformations" class="section level2" number="13.10">
<h2><span class="header-section-number">13.10</span> Data transformations</h2>
<p>We can formally assess whether a distribution is normal.
Below is a complete worked out example on how to test for the assumption of normality and equality of variance. The example is taken from <span class="citation">(Andy Field <a href="#ref-dsur" role="doc-biblioref">2012</a>)</span>.</p>
<div id="read-in-the-festival-dataset-from-dsur" class="section level3" number="13.10.1">
<h3><span class="header-section-number">13.10.1</span> Read in the ‘Festival Dataset’ from <span class="citation">(Andy Field <a href="#ref-dsur" role="doc-biblioref">2012</a>)</span>:</h3>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb844-1"><a href="assumptions.html#cb844-1"></a>dlf &lt;-<span class="st"> </span><span class="kw">read_delim</span>(<span class="dt">file =</span> here<span class="op">::</span><span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, </span>
<span id="cb844-2"><a href="assumptions.html#cb844-2"></a>                                   <span class="st">&quot;DownloadFestival.dat&quot;</span>), </span>
<span id="cb844-3"><a href="assumptions.html#cb844-3"></a>                                   <span class="dt">delim =</span>  <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">na =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot; &quot;</span>))</span></code></pre></div>
<pre><code>## 
## -- Column specification --------------------------------------------------------
## cols(
##   ticknumb = col_double(),
##   gender = col_character(),
##   day1 = col_double(),
##   day2 = col_double(),
##   day3 = col_double()
## )</code></pre>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb846-1"><a href="assumptions.html#cb846-1"></a>dlf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   ticknumb gender  day1  day2   day3
##      &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     2111 Male    2.64  1.35  1.61 
## 2     2229 Female  0.97  1.41  0.290
## 3     2338 Male    0.84 NA    NA</code></pre>
<p>Checking missing values, distributions and detecting outliers</p>
<div class="sourceCode" id="cb848"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb848-1"><a href="assumptions.html#cb848-1"></a><span class="kw">sum</span>(<span class="kw">is.na</span>(dlf))</span></code></pre></div>
<pre><code>## [1] 1233</code></pre>
<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb850-1"><a href="assumptions.html#cb850-1"></a>x &lt;-<span class="st"> </span><span class="kw">summary</span>(dlf)</span>
<span id="cb850-2"><a href="assumptions.html#cb850-2"></a>min_maxs &lt;-<span class="st"> </span>x[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>), <span class="kw">c</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">5</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>()</span></code></pre></div>
<pre><code>##       day1             day2             day3       
##  Min.   : 0.020   Min.   :0.0000   Min.   :0.0200  
##  Max.   :20.020   Max.   :3.4400   Max.   :3.4100</code></pre>
<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb852-1"><a href="assumptions.html#cb852-1"></a>naniar<span class="op">::</span><span class="kw">vis_miss</span>(dlf)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Detecting an outlier with a histogram</p>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb853-1"><a href="assumptions.html#cb853-1"></a>hist.outlier &lt;-<span class="st"> </span><span class="kw">ggplot</span>(dlf, <span class="kw">aes</span>(day1)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb853-2"><a href="assumptions.html#cb853-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y=</span>..density..), </span>
<span id="cb853-3"><a href="assumptions.html#cb853-3"></a>                 <span class="dt">colour=</span><span class="st">&quot;black&quot;</span>, </span>
<span id="cb853-4"><a href="assumptions.html#cb853-4"></a>                 <span class="dt">fill=</span><span class="st">&quot;white&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb853-5"><a href="assumptions.html#cb853-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Hygiene score on day 1&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Density&quot;</span>) <span class="op">+</span></span>
<span id="cb853-6"><a href="assumptions.html#cb853-6"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span>
<span id="cb853-7"><a href="assumptions.html#cb853-7"></a>hist.outlier</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p><code>{ggplot2}</code> works best with long or so-called stacked datasets.</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb855-1"><a href="assumptions.html#cb855-1"></a>dlf_long &lt;-<span class="st"> </span>dlf <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb855-2"><a href="assumptions.html#cb855-2"></a><span class="st">  </span>tidyr<span class="op">::</span><span class="kw">gather</span>(day1<span class="op">:</span>day3, <span class="dt">key =</span> <span class="st">&quot;days&quot;</span>, <span class="dt">value =</span> <span class="st">&quot;hygiene_score&quot;</span>)</span>
<span id="cb855-3"><a href="assumptions.html#cb855-3"></a>dlf_long</span></code></pre></div>
<pre><code>## # A tibble: 2,430 x 4
##    ticknumb gender days  hygiene_score
##       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;
##  1     2111 Male   day1           2.64
##  2     2229 Female day1           0.97
##  3     2338 Male   day1           0.84
##  4     2384 Female day1           3.03
##  5     2401 Female day1           0.88
##  6     2405 Male   day1           0.85
##  7     2467 Female day1           1.56
##  8     2478 Female day1           3.02
##  9     2490 Male   day1           2.29
## 10     2504 Female day1           1.11
## # ... with 2,420 more rows</code></pre>
<p>Boxplots with outlier</p>
<pre><code>## Warning: Removed 1233 rows containing non-finite values (stat_boxplot).</code></pre>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="exercise-1-removing-outliers-and-distributions" class="section level3 unnumbered" number="">
<h3><mark><strong>EXERCISE 1; Removing outliers and distributions</strong></mark></h3>
<ol style="list-style-type: upper-alpha">
<li><p>Remove the outlier identified above</p></li>
<li><p>Create a new series of boxplots split by <code>gender</code> and <code>day</code></p></li>
<li><p>Create a plot showing all the data, except for the one outlier you just removed. Think about whether you need to fix overplotting by some smart trick.</p></li>
<li><p>Create a plot showing the distributions for <code>hygiene_score</code> for each day. Disregard any difference in gender. <em>Is this a safe assumtion?</em></p></li>
<li><p>Are these distributions following a Gaussian bell-shaped curve?</p></li>
</ol>
</div>
<div id="exercise-end---2" class="section level3 unnumbered" number="">
<h3>—- EXERCISE END —-</h3>
</div>
<div id="how-would-the-distribution-look-if-it-were-gaussian" class="section level3" number="13.10.2">
<h3><span class="header-section-number">13.10.2</span> How would the distribution look if it were Gaussian?</h3>
<p>We add the simulated normal distributions to the original dataframe and create a new stacked version. We set the seed for reproducibility.</p>
<p>Compare the real distributions to the ‘predicted’ distributions. Try discribing what you see.</p>
<div class="sourceCode" id="cb858"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb858-1"><a href="assumptions.html#cb858-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb858-2"><a href="assumptions.html#cb858-2"></a><span class="co">## add normal distribution to the data (based on observed mean and sd per day)</span></span>
<span id="cb858-3"><a href="assumptions.html#cb858-3"></a>dlf_norm &lt;-<span class="st"> </span>dlf <span class="op">%&gt;%</span></span>
<span id="cb858-4"><a href="assumptions.html#cb858-4"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb858-5"><a href="assumptions.html#cb858-5"></a>    <span class="dt">norm_day_1 =</span> <span class="kw">rnorm</span>(</span>
<span id="cb858-6"><a href="assumptions.html#cb858-6"></a>      <span class="dt">mean =</span> <span class="kw">mean</span>(dlf<span class="op">$</span>day1, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>), </span>
<span id="cb858-7"><a href="assumptions.html#cb858-7"></a>      <span class="dt">n =</span> <span class="kw">nrow</span>(dlf), </span>
<span id="cb858-8"><a href="assumptions.html#cb858-8"></a>      <span class="dt">sd =</span> <span class="kw">sd</span>(dlf<span class="op">$</span>day1, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)),</span>
<span id="cb858-9"><a href="assumptions.html#cb858-9"></a>    <span class="dt">norm_day_2 =</span> <span class="kw">rnorm</span>(</span>
<span id="cb858-10"><a href="assumptions.html#cb858-10"></a>      <span class="dt">mean =</span> <span class="kw">mean</span>(dlf<span class="op">$</span>day2, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>), </span>
<span id="cb858-11"><a href="assumptions.html#cb858-11"></a>      <span class="dt">n =</span> <span class="kw">nrow</span>(dlf), </span>
<span id="cb858-12"><a href="assumptions.html#cb858-12"></a>      <span class="dt">sd =</span> <span class="kw">sd</span>(dlf<span class="op">$</span>day2, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)),</span>
<span id="cb858-13"><a href="assumptions.html#cb858-13"></a>    <span class="dt">norm_day_3 =</span> <span class="kw">rnorm</span>(</span>
<span id="cb858-14"><a href="assumptions.html#cb858-14"></a>      <span class="dt">mean =</span> <span class="kw">mean</span>(dlf<span class="op">$</span>day3, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>), </span>
<span id="cb858-15"><a href="assumptions.html#cb858-15"></a>      <span class="dt">n =</span> <span class="kw">nrow</span>(dlf), </span>
<span id="cb858-16"><a href="assumptions.html#cb858-16"></a>      <span class="dt">sd =</span> <span class="kw">sd</span>(dlf<span class="op">$</span>day3, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span></span>
<span id="cb858-17"><a href="assumptions.html#cb858-17"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(gender, norm_day_<span class="dv">1</span><span class="op">:</span>norm_day_<span class="dv">3</span>) <span class="op">%&gt;%</span></span>
<span id="cb858-18"><a href="assumptions.html#cb858-18"></a><span class="st">  </span>tidyr<span class="op">::</span><span class="kw">gather</span>(norm_day_<span class="dv">1</span><span class="op">:</span>norm_day_<span class="dv">3</span>, </span>
<span id="cb858-19"><a href="assumptions.html#cb858-19"></a>                <span class="dt">key =</span> <span class="st">&quot;days&quot;</span>, </span>
<span id="cb858-20"><a href="assumptions.html#cb858-20"></a>                <span class="dt">value =</span> <span class="st">&quot;norm_hygiene_score&quot;</span>)</span>
<span id="cb858-21"><a href="assumptions.html#cb858-21"></a>  </span>
<span id="cb858-22"><a href="assumptions.html#cb858-22"></a></span>
<span id="cb858-23"><a href="assumptions.html#cb858-23"></a><span class="co">## add to plot</span></span>
<span id="cb858-24"><a href="assumptions.html#cb858-24"></a>dlf_long <span class="op">%&gt;%</span></span>
<span id="cb858-25"><a href="assumptions.html#cb858-25"></a><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(<span class="op">!</span>hygiene_score <span class="op">&gt;</span><span class="st"> </span><span class="dv">19</span>) <span class="op">%&gt;%</span></span>
<span id="cb858-26"><a href="assumptions.html#cb858-26"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> hygiene_score)) <span class="op">+</span></span>
<span id="cb858-27"><a href="assumptions.html#cb858-27"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> days)) <span class="op">+</span></span>
<span id="cb858-28"><a href="assumptions.html#cb858-28"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">data =</span> dlf_norm, <span class="kw">aes</span>(<span class="dt">x =</span> norm_hygiene_score,</span>
<span id="cb858-29"><a href="assumptions.html#cb858-29"></a>                                    <span class="dt">colour =</span> days)) <span class="op">+</span></span>
<span id="cb858-30"><a href="assumptions.html#cb858-30"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>days)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
</div>
<div id="q-q-plot" class="section level3" number="13.10.3">
<h3><span class="header-section-number">13.10.3</span> Q-Q Plot</h3>
<p>The quantile-quantile plot shows the realtionship between the true data distribution and the estimated distribution, under the assumption of Gaussian (or normal) distribution.</p>
<p>Q-Q plot for day 1</p>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb859-1"><a href="assumptions.html#cb859-1"></a><span class="co">## see the file ggqq.R for the function definition</span></span>
<span id="cb859-2"><a href="assumptions.html#cb859-2"></a><span class="kw">source</span>(<span class="dt">file =</span> here<span class="op">::</span><span class="kw">here</span>(<span class="st">&quot;code&quot;</span>, <span class="st">&quot;ggqq.R&quot;</span>))</span>
<span id="cb859-3"><a href="assumptions.html#cb859-3"></a>gg_qq_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">gg_qq</span>(dlf<span class="op">$</span>day1)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<div class="sourceCode" id="cb860"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb860-1"><a href="assumptions.html#cb860-1"></a>gg_qq_<span class="dv">1</span></span></code></pre></div>
<pre><code>##      25%      75% 
## 1.770000 0.681997</code></pre>
<p>Q-Q Day 2</p>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb862-1"><a href="assumptions.html#cb862-1"></a>gg_qq_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">gg_qq</span>(dlf<span class="op">$</span>day2)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<div class="sourceCode" id="cb863"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb863-1"><a href="assumptions.html#cb863-1"></a>gg_qq_<span class="dv">2</span></span></code></pre></div>
<pre><code>##       25%       75% 
## 0.8725000 0.6857035</code></pre>
<p>Clearly not normally distributed</p>
<p>Q-Q Day 3</p>
<div class="sourceCode" id="cb865"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb865-1"><a href="assumptions.html#cb865-1"></a><span class="kw">gg_qq</span>(dlf<span class="op">$</span>day3)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<pre><code>##       25%       75% 
## 0.9825000 0.8043117</code></pre>
<p>Not evenly distributed and not a good fit to the estimated distribution. Not normally distributed</p>
</div>
</div>
<div id="skewness-and-kurtosis" class="section level2" number="13.11">
<h2><span class="header-section-number">13.11</span> Skewness and kurtosis</h2>
<p>Skewness and kurtosis are parameters that display the deviation from normality looking at the shape of the distribution polynom. A distribution with an absolute <code>skew.2SE</code> &gt; 1 is significantly skewed and not normal. A distribution with an absolute <code>kurt.2SE</code> &gt; 1 has significant kurtosis and is not normally distributed.</p>
<p><code>kurt.2SE</code> and <code>skew.2SE</code> are calculated from</p>
<ul>
<li><span class="math inline">\(kurt.2SE = kurt / 2*(standard.error)\)</span></li>
<li><span class="math inline">\(skew.2SE = skew / 2*(standard.error)\)</span></li>
</ul>
</div>
<div id="shapiro-wilk-test" class="section level2" number="13.12">
<h2><span class="header-section-number">13.12</span> <code>Shapiro-Wilk test</code></h2>
<p>To test for normality we can use the <code>Shapiro-Wilk test</code>. This test checks whether the deviation from normality is significant (H0) or not (H1),</p>
<ul>
<li>p-value &lt; 0.05 means that the distribution is significantly different from a normal distribution: assumption “the distribution is not normal”</li>
<li>p-value &gt; 0.05 means that the distribution is not significantly different from normal: assumption “the distribution cannot be proved to deviate from normal”</li>
</ul>
</div>
<div id="exercise-2-discriptive-statistics" class="section level2" number="13.13">
<h2><span class="header-section-number">13.13</span> <mark><strong>EXERCISE 2; Discriptive statistics</strong> </mark></h2>
<p>Here we use <code>stat.desc()</code> function from the <code>{pastecs}</code> package, to get descriptive statistics for a dataframe or a variable.</p>
<ol style="list-style-type: upper-alpha">
<li><p>Look at the help function of <code>stat.desc()</code>. what do the arguments <code>basic</code> and <code>norm</code> do?</p></li>
<li><p>Run the <code>stat.desc</code> function on the <code>dlf</code> dataframe. Try getting descriptive statitics for each day seperatly</p></li>
</ol>
<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb867-1"><a href="assumptions.html#cb867-1"></a><span class="kw">library</span>(pastecs)</span>
<span id="cb867-2"><a href="assumptions.html#cb867-2"></a><span class="kw">round</span>(<span class="kw">stat.desc</span>(dlf[, <span class="kw">c</span>(<span class="st">&quot;day1&quot;</span>, <span class="st">&quot;day2&quot;</span>, <span class="st">&quot;day3&quot;</span>)], <span class="dt">basic =</span> <span class="ot">FALSE</span>, <span class="dt">norm =</span> <span class="ot">TRUE</span>), <span class="dt">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##                day1  day2  day3
## median        1.790 0.790 0.760
## mean          1.771 0.955 0.977
## SE.mean       0.024 0.044 0.064
## CI.mean.0.95  0.048 0.087 0.127
## var           0.482 0.513 0.504
## std.dev       0.694 0.716 0.710
## coef.var      0.392 0.750 0.727
## skewness     -0.003 1.097 1.008
## skew.2SE     -0.018 3.653 2.309
## kurtosis     -0.424 0.829 0.595
## kurt.2SE     -1.235 1.386 0.686
## normtest.W    0.996 0.908 0.908
## normtest.p    0.032 0.000 0.000</code></pre>
<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb869-1"><a href="assumptions.html#cb869-1"></a><span class="co">## or </span></span>
<span id="cb869-2"><a href="assumptions.html#cb869-2"></a>descriptives &lt;-<span class="st"> </span><span class="kw">map</span>(dlf, stat.desc, <span class="dt">basic =</span> <span class="ot">FALSE</span>, <span class="dt">norm =</span> <span class="ot">TRUE</span>) </span></code></pre></div>
<div id="exercise-end---3" class="section level3 unnumbered" number="">
<h3>—- EXERCISE END —-</h3>
</div>
</div>
<div id="levenes-test" class="section level2" number="13.14">
<h2><span class="header-section-number">13.14</span> Levene’s Test</h2>
<p>The Levene Test can be used to asses whether the variance for two or more distributions is equal. As always, when using the Levene Test it is important to assess also visually if the outcome of the statitical test makes sense.</p>
<div class="sourceCode" id="cb870"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb870-1"><a href="assumptions.html#cb870-1"></a><span class="kw">leveneTest</span>(dlf<span class="op">$</span>day1, dlf<span class="op">$</span>day2)</span>
<span id="cb870-2"><a href="assumptions.html#cb870-2"></a><span class="kw">leveneTest</span>(<span class="dt">data =</span> dlf_long, hygiene_score <span class="op">~</span><span class="st"> </span>days)</span>
<span id="cb870-3"><a href="assumptions.html#cb870-3"></a><span class="co"># leveneTest(data = dlf_long, hygiene_score ~ days * gender)</span></span>
<span id="cb870-4"><a href="assumptions.html#cb870-4"></a></span>
<span id="cb870-5"><a href="assumptions.html#cb870-5"></a>dlf_long <span class="op">%&gt;%</span></span>
<span id="cb870-6"><a href="assumptions.html#cb870-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> hygiene_score, <span class="dt">y =</span> ticknumb)) <span class="op">+</span></span>
<span id="cb870-7"><a href="assumptions.html#cb870-7"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> days)) <span class="op">+</span></span>
<span id="cb870-8"><a href="assumptions.html#cb870-8"></a><span class="st">  </span><span class="kw">facet_wrap</span>(days <span class="op">~</span><span class="st"> </span>gender, <span class="dt">nrow =</span> <span class="dv">3</span>)</span></code></pre></div>
<p>A significant Levene Test indicates that the H0 = variances are equal does not hold and can be rejected. So if we look at the days as a factor, variance is equal over the days, but if we also take gender into consideration, we see that the variances between all groups are not equal.</p>
</div>
<div id="transforming-data" class="section level2" number="13.15">
<h2><span class="header-section-number">13.15</span> Transforming data</h2>
<ul>
<li>To remove skewness or kurtosis</li>
<li>Apply the <strong><em>same</em></strong> transformation to <strong><em>all variables</em></strong></li>
<li>After transformation and analysis or especially with predictions, sometimes you need to inverse-transform to make sense of the outcome.</li>
<li>It can be a time comsuming process: ‘trial-and-error’</li>
</ul>
<div id="log-square-root-and-inverse" class="section level3" number="13.15.1">
<h3><span class="header-section-number">13.15.1</span> Log, square root and inverse</h3>
<p>Sometimes skewness can be greatly reduced by applying a log (10, n or 2) transformation to the data.</p>
</div>
<div id="center-and-scale" class="section level3" number="13.15.2">
<h3><span class="header-section-number">13.15.2</span> Center and scale</h3>
<p>Centering and scaling is the most simple transfromation.
When centering a variable, the average value is subtracted from all the values, resulting in a zero mean. To scale the data, each value of the variable is divided by its standard deviation. We will see below in an EXERCISE how to explore whether transformations work.</p>
</div>
<div id="exercise-3-exploring-data-with-dlookr-transformations." class="section level3 unnumbered" number="">
<h3><mark><strong>EXERCISE 3; Exploring data with <code>{dlookr}</code>, transformations.</strong></mark></h3>
<ol style="list-style-type: upper-alpha">
<li><p>The <code>{dlookr}</code> package can automate a number of exploratory tasks. Have a look at the vignette here:
<a href="https://cran.r-project.org/web/packages/dlookr/vignettes/EDA.html" class="uri">https://cran.r-project.org/web/packages/dlookr/vignettes/EDA.html</a></p></li>
<li><p>Look at the <code>help()</code> for functions
<code>normality()</code> and
<code>plot_normality()</code> of the <code>{dlookr}</code> package. Try confirming with these functions what we already know about normality of the <code>hygiene_score</code> by <code>day</code>.</p></li>
</ol>
<p><strong>Remember, the H0 for Shapiro: ‘Distribution == Normal’, so a significant P rejects the H0 and therefore indicates deviance from normality.</strong></p>
<ol start="3" style="list-style-type: upper-alpha">
<li>Does this confirm the previous analysis? Is there a candidate for transformation you could try?</li>
</ol>
</div>
<div id="exercise-end---4" class="section level3 unnumbered" number="">
<h3>—- EXERCISE END —-</h3>
</div>
</div>
<div id="formal-inference-of-the-festival-data" class="section level2" number="13.16">
<h2><span class="header-section-number">13.16</span> Formal inference of the Festival data</h2>
<p>Let’s assume we can make the data fairly normal by doing a <span class="math inline">\(\sqrt{yi}\)</span> transformation on every measured <code>hygiene_score</code>. When we do this transformation, the distribution for day 2 and 3 approaches normality much better, but for Day 1 it slightly deteriorates. Let’s stick with this for now.</p>
<p>Under the assumption of normality, and the realization that this is not completely met, we can do a two way anova on the data. We include gender and days as predictors to the transformed hygiene score.</p>
<div class="sourceCode" id="cb871"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb871-1"><a href="assumptions.html#cb871-1"></a>lm_festival &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> dlf_long_new, hygiene_score_sqrt <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>days)</span>
<span id="cb871-2"><a href="assumptions.html#cb871-2"></a></span>
<span id="cb871-3"><a href="assumptions.html#cb871-3"></a><span class="kw">summary</span>(lm_festival)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = hygiene_score_sqrt ~ gender + days, data = dlf_long_new)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.20437 -0.19688  0.02092  0.20384  0.99193 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.34579    0.01288  104.46  &lt; 2e-16 ***
## genderMale  -0.11693    0.01813   -6.45 1.63e-10 ***
## daysday2    -0.39049    0.02173  -17.97  &lt; 2e-16 ***
## daysday3    -0.37095    0.02969  -12.49  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3065 on 1192 degrees of freedom
## Multiple R-squared:  0.2781,	Adjusted R-squared:  0.2763 
## F-statistic: 153.1 on 3 and 1192 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb873"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb873-1"><a href="assumptions.html#cb873-1"></a><span class="kw">anova</span>(lm_festival) </span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: hygiene_score_sqrt
##             Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## gender       1   4.477  4.4766  47.642 8.296e-12 ***
## days         2  38.670 19.3348 205.766 &lt; 2.2e-16 ***
## Residuals 1192 112.006  0.0940                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>From this output we see (under the earlier mentioned restrictions, uncertainties and assumptions) that both gender and days have a significant affect on the outcome for the (transformed) hygiene score.</p>
<p>We can include the interaction between these predictors by specifying <code>gender * days</code> in the model. There is no significant interaction. Can you formulate in your own words what this could mean?</p>
<div class="sourceCode" id="cb875"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb875-1"><a href="assumptions.html#cb875-1"></a>lm_festival &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> dlf_long_new, hygiene_score_sqrt <span class="op">~</span><span class="st"> </span>gender <span class="op">*</span><span class="st"> </span>days)</span>
<span id="cb875-2"><a href="assumptions.html#cb875-2"></a><span class="kw">anova</span>(lm_festival)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: hygiene_score_sqrt
##               Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## gender         1   4.477  4.4766  47.619 8.393e-12 ***
## days           2  38.670 19.3348 205.670 &lt; 2.2e-16 ***
## gender:days    2   0.136  0.0679   0.722     0.486    
## Residuals   1190 111.870  0.0940                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>A post hoc analysis to see where the differences are: I illustrate two different way, using two different packages. Bonferroni corrrection is to compensate for multiple comparisons (in this case we have three comparisons for ‘days’ and one comparison for ‘gender’). I will not go into detail here.</p>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb877-1"><a href="assumptions.html#cb877-1"></a><span class="kw">library</span>(agricolae)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;agricolae&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:e1071&#39;:
## 
##     kurtosis, skewness</code></pre>
<div class="sourceCode" id="cb880"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb880-1"><a href="assumptions.html#cb880-1"></a><span class="kw">library</span>(emmeans)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;emmeans&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:devtools&#39;:
## 
##     test</code></pre>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb883-1"><a href="assumptions.html#cb883-1"></a>emmeans<span class="op">::</span><span class="kw">emmeans</span>(lm_festival, <span class="op">~</span>days)</span></code></pre></div>
<pre><code>## NOTE: Results may be misleading due to involvement in interactions</code></pre>
<pre><code>##  days emmean     SE   df lower.CL upper.CL
##  day1  1.289 0.0111 1190    1.267    1.310
##  day2  0.893 0.0193 1190    0.855    0.930
##  day3  0.916 0.0278 1190    0.862    0.971
## 
## Results are averaged over the levels of: gender 
## Confidence level used: 0.95</code></pre>
<div class="sourceCode" id="cb886"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb886-1"><a href="assumptions.html#cb886-1"></a>emmeans<span class="op">::</span><span class="kw">emmeans</span>(lm_festival, <span class="op">~</span>gender)</span></code></pre></div>
<pre><code>## NOTE: Results may be misleading due to involvement in interactions</code></pre>
<pre><code>##  gender emmean     SE   df lower.CL upper.CL
##  Female   1.10 0.0156 1190    1.065     1.13
##  Male     0.97 0.0179 1190    0.934     1.00
## 
## Results are averaged over the levels of: days 
## Confidence level used: 0.95</code></pre>
<div class="sourceCode" id="cb889"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb889-1"><a href="assumptions.html#cb889-1"></a>agricolae<span class="op">::</span><span class="kw">LSD.test</span>(lm_festival, <span class="st">&quot;days&quot;</span>, <span class="dt">console =</span> <span class="ot">TRUE</span>, <span class="dt">p.adj =</span> <span class="st">&quot;bonferroni&quot;</span>)</span></code></pre></div>
<pre><code>## 
## Study: lm_festival ~ &quot;days&quot;
## 
## LSD t Test for hygiene_score_sqrt 
## P value adjustment method: bonferroni 
## 
## Mean Square Error:  0.09400872 
## 
## days,  means and individual ( 95 %) CI
## 
##      hygiene_score_sqrt       std   r       LCL       UCL       Min      Max
## day1          1.3002586 0.2832933 809 1.2791091 1.3214080 0.1414214 1.920937
## day2          0.9092350 0.3670301 264 0.8722119 0.9462580 0.0000000 1.854724
## day3          0.9216026 0.3580432 123 0.8673624 0.9758429 0.1414214 1.846619
## 
## Alpha: 0.05 ; DF Error: 1190
## Critical Value of t: 2.39737 
## 
## Groups according to probability of means differences and alpha level( 0.05 )
## 
## Treatments with the same letter are not significantly different.
## 
##      hygiene_score_sqrt groups
## day1          1.3002586      a
## day3          0.9216026      b
## day2          0.9092350      b</code></pre>
<div class="sourceCode" id="cb891"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb891-1"><a href="assumptions.html#cb891-1"></a>agricolae<span class="op">::</span><span class="kw">LSD.test</span>(lm_festival, <span class="st">&quot;gender&quot;</span>, <span class="dt">console =</span> <span class="ot">TRUE</span>, <span class="dt">p.adj =</span> <span class="st">&quot;bonferroni&quot;</span>)</span></code></pre></div>
<pre><code>## 
## Study: lm_festival ~ &quot;gender&quot;
## 
## LSD t Test for hygiene_score_sqrt 
## P value adjustment method: bonferroni 
## 
## Mean Square Error:  0.09400872 
## 
## gender,  means and individual ( 95 %) CI
## 
##        hygiene_score_sqrt       std   r      LCL      UCL       Min      Max
## Female           1.224662 0.3604338 721 1.202259 1.247065 0.1414214 1.920937
## Male             1.099628 0.3471971 475 1.072027 1.127229 0.0000000 1.892089
## 
## Alpha: 0.05 ; DF Error: 1190
## Critical Value of t: 1.961959 
## 
## Groups according to probability of means differences and alpha level( 0.05 )
## 
## Treatments with the same letter are not significantly different.
## 
##        hygiene_score_sqrt groups
## Female           1.224662      a
## Male             1.099628      b</code></pre>
<p>There is lot we can bring to the table to discuss this formal inference of this dataset. We know that there is a problem with assuming normally ditributed data. Therefore it always wise to check the models fit. After model checking you can dicide to apply a alternative model. For instance we can use a non-paramteric test or a robuster analysis of variance. How you do this is out of scope for this course.
What I can illustrate though is one way to check whether this anova model is appropriatly catching all variance in the data. One way to do this is by checking the models residuals.</p>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb893-1"><a href="assumptions.html#cb893-1"></a><span class="kw">tibble</span>(<span class="dt">resids =</span> lm_festival<span class="op">$</span>residuals,</span>
<span id="cb893-2"><a href="assumptions.html#cb893-2"></a>          <span class="dt">fitted =</span> lm_festival<span class="op">$</span>fitted.values) <span class="op">%&gt;%</span></span>
<span id="cb893-3"><a href="assumptions.html#cb893-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> fitted,</span>
<span id="cb893-4"><a href="assumptions.html#cb893-4"></a>             <span class="dt">y =</span> resids)) <span class="op">+</span></span>
<span id="cb893-5"><a href="assumptions.html#cb893-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">alpha =</span> <span class="fl">0.4</span>) <span class="op">+</span></span>
<span id="cb893-6"><a href="assumptions.html#cb893-6"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<div class="sourceCode" id="cb894"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb894-1"><a href="assumptions.html#cb894-1"></a><span class="kw">plot</span>(lm_festival)</span></code></pre></div>
<p><img src="ch11-assumptions_files/figure-html/unnamed-chunk-36-2.png" width="672" /><img src="ch11-assumptions_files/figure-html/unnamed-chunk-36-3.png" width="672" /><img src="ch11-assumptions_files/figure-html/unnamed-chunk-36-4.png" width="672" /><img src="ch11-assumptions_files/figure-html/unnamed-chunk-36-5.png" width="672" /></p>
<p>The residuals vs fitted plot shows a even distribution above and below the red line, this is good. It also shows that the variance over the different point-series is equally large. It does show some sytematic pattern, the series of dots being equally lined up, which shows that the model was unable to catch all information in the data.</p>
<p>Calling plot on a model object in R also shows a number of diagnostic plots to assess model fit. Here we see that the Q-Q plot of the residuals: the points should be on the line for the assumption of nromality to be met.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-dsur">
<p>Andy Field, Zoe Field, Jeremy Miles. 2012. <em>Discovering Statistics Using R</em>. SAGE. <a href="https://uk.sagepub.com/en-gb/eur/discovering-statistics-using-r/book236067">https://uk.sagepub.com/en-gb/eur/discovering-statistics-using-r/book236067</a>.</p>
</div>
<div id="ref-adventr">
<p>Field, Andy. 2019. <em>Adventr: Interactive Tutorials to Accompany an Adventure in Statistics</em>. <a href="http://milton-the-cat.rocks/home/adventr.html">http://milton-the-cat.rocks/home/adventr.html</a>.</p>
</div>
<div id="ref-apm">
<p>Kuhn, Max, and Kjell Johnson. 2018. <em>AppliedPredictiveModeling: Functions and Data Sets for ’Applied Predictive Modeling’</em>. <a href="https://CRAN.R-project.org/package=AppliedPredictiveModeling">https://CRAN.R-project.org/package=AppliedPredictiveModeling</a>.</p>
</div>
<div id="ref-rethinking">
<p>McElreath, Richard. 2020. <em>Rethinking: Statistical Rethinking Book Package - Second Ed.</em></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="importingdata.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sampling-bootstrapping.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/uashogeschoolutrecht/staRters/edit/master/ch11-assumptions.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["exploratory_data_analysis.pdf", "exploratory_data_analysis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
